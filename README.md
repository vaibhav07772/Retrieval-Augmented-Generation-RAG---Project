# Retrieval-Augmented-Generation-RAG---Project
Retriever And Chain With Langchain--->

# ğŸ“š Retrieval-Augmented Generation (RAG) using LangChain + Ollama + FAISS  
This project implements a **fully local RAG pipeline** using:

- ğŸ§  **Ollama LLaMA2** as the LLM  
- ğŸ“„ **PDF Loader** for document ingestion  
- âœ‚ï¸ **Recursive Text Splitter** for chunking  
- ğŸ” **FAISS Vector Database** for semantic search  
- ğŸ”— **LangChain Retrieval Chain** for contextual Q&A  

This RAG chatbot answers user questions **using only the given PDF** and provides accurate, context-aware responses.

---

## ğŸš€ Features
- Load any **PDF document**
- Split document into optimized **text chunks**
- Generate **embeddings locally** using Ollama
- Store embeddings into **FAISS vector database**
- Build a **retrieval pipeline**
- Query using natural language
- Get **context-driven answers** from LLaMA2 (Ollama)

---
## ğŸ› ï¸ Tech Stack
| Component | Library / Model |
|----------|------------------|
| LLM | Ollama (LLaMA2) |
| Embeddings | OllamaEmbeddings |
| Vector DB | FAISS |
| Framework | LangChain |
| Document Loader | PyPDFLoader |
| Text Splitter | RecursiveCharacterTextSplitter |

---

## ğŸ“‚ Project Structure
RAG-Project/
â”‚â”€â”€ Data/
â”‚ â””â”€â”€ Data Science Interview Preparation(#DAY 04).pdf
â”‚â”€â”€ rag_app.py
â”‚â”€â”€ README.md

## ğŸ“‚ Project Structure

